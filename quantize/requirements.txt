torch==2.3.0
transformers
huggingface_hub
optimum
# For AWQ
autoawq
# For GPTQ
auto-gptq
einops
accelerate
